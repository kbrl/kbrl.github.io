---
layout: page
title: Schedule
permalink: /schedule/
---


<link href="https://kbrl.github.io/img/general.css" rel="stylesheet"></link>

<table class="demo">
	<caption></caption>
	<thead>
	<tr>
		<th>Time<br>(JST, GMT+09:00)</th>
		<th>Category</th>
		<th>Title & Speaker(s)</th>
	</tr>
	</thead>
	<tbody>
	<tr>
		<td>&nbsp;08:50</td>
		<td>&nbsp;Opening Remarks</td>
		<td>&nbsp;<a href="https://kbrl.github.io/organizers/">KBRL Organizers</a></td>
	</tr>
	<tr>
		<td>&nbsp;09:00</td>
		<td>&nbsp;Invited Talk</td>
		<td>&nbsp;<a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/svlevine.html">Sergey Levine</a>, Assistant Professor, UC Berkeley</td>
	</tr>
	<tr>
		<td>&nbsp;09:30</td>
		<td>Contributed Talk</td>
		<td>I-Chao Shen, Shu-Hsuan Hsu, Bing-Yu Chen<br><b>Transferring Deep Reinforcement Learning with Adversarial Objective and Augmentation</b>  (<a href="tmp">PDF</a>)</td>
	</tr>
	<tr>
		<td>&nbsp;09:50</td>
		<td>Contributed Talk</td>
		<td>Prithviraj V Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark Riedl<br><b>How To Avoid Being Eaten By a Grue: Exploration Strategies for Text-Adventure Agents</b>
 (<a href="tmp">PDF</a>)</td>
	</tr>
	<tr>
		<td>&nbsp;10:10</td>
		<td>Break</td>
		<td></td>
	</tr>	
	<tr>
		<td>&nbsp;10:30</td>
		<td>&nbsp;Invited Talk</td>
		<td>&nbsp;<a href="https://www.cs.princeton.edu/~karthikn/">Karthik Narasimhan</a>, Assistant Professor, Computer Science, Princeton NLP</td>
	</tr>			
	<tr>
		<td>&nbsp;11:00</td>
		<td>Contributed Talk</td>
		<td>Bernardo Esteves, Francisco S. Melo<br><b>Revisiting “Recurrent World Models Facilitate Policy Evolution”</b> (<a href="tmp">PDF</a>)</td>
	</tr>	
	<tr>
		<td>&nbsp;11:20</td>
		<td>Contributed Talk</td>
		<td>Duc Thien Nguyen, Desmond Cai, Shiau Hong Lim, Laura Wynter<br><b>Deep Recurrent Policy Search for Portfolio Optimization</b></td>	
	</tr>
	<tr>
		<td>&nbsp;11:40</td>
		<td>Contributed Talk</td>
		<td>Jakob J Hollenstein, Sayantan Auddy, Matteo Saveriano, Erwan Renaudo, Justus Piater<br><b>How do Offline Measures for Exploration in Reinforcement Learning behave?</b></td>
	</tr>
	<tr>
		<td>&nbsp;12:00</td>
		<td>Lunch Break</td>
		<td></td>
	</tr>		
	<tr>
		<td>&nbsp;13:00</td>
		<td>&nbsp;Invited Talk</td>
		<td>&nbsp;<a href="https://www.linkedin.com/in/alexander-gray-b554b64/">Alexander Gray</a>, IBM Reserach</td>
	</tr>		
	<tr>
		<td>&nbsp;13:30</td>
		<td>Contributed Talk</td>
		<td>Corentin Sautier, Don Joven Agravante, Michiaki Tatsubori<br><b>State Prediction in TextWorld with a Predicate-Logic Pointer Network Architecture</b></td>
	</tr>
	<tr>
		<td>&nbsp;13:50</td>
		<td>Contributed Talk</td>
		<td>Minori Narita, Daiki Kimura<br><b>Learning from Failure: Introducing Failure Ratio in Reinforcement Learning</b></td>
	</tr>
	<tr>
		<td>&nbsp;14:10</td>
		<td>Contributed Talk</td>
		<td>Corentin Sautier, Don Joven Agravante, Michiaki Tatsubori<br><b>Towards Logical Model-based Reinforcement Learning: Lifted Operator Models</b></td>
	</tr>
	<tr>
		<td>&nbsp;14:30</td>
		<td>&nbsp;Invited Talk</td>
		<td>&nbsp;<a href="https://scholar.google.co.jp/citations?user=Khb7qw8AAAAJ&hl=ja">Masashi Hamaya</a>, Omron</td>
	</tr>
	<tr>
		<td>&nbsp;15:00</td>
		<td>Break</td>
		<td></td>
	</tr>	
	<tr>
		<td>&nbsp;15:20</td>
		<td>Contributed Talk</td>
		<td>Corentin Sautier, Don Joven Agravante, Michiaki Tatsubori<br><b>Towards Logical Model-based Reinforcement Learning: Lifted Operator Models</b></td>
	</tr>
	<tr>
		<td>&nbsp;15:40</td>
		<td>Contributed Talk</td>
		<td>Daiki Kimura, Subhajit Chaudhury, Akifumi Wachi, Ryosuke Kohita, Asim Munawar, Michiaki Tatsubori, Alexander G Gray<br><b>Reinforcement Learning with External Knowledge by using Logical Neural Networks</b></td>
	</tr>
	<tr>
		<td>&nbsp;16:00</td>
		<td>&nbsp;Invited Talk</td>
		<td>&nbsp;<a href="https://ogata-lab.jp/">Tetsuya Ogata</a>, Waseda University</td>
	</tr>
	<tr>
		<td>&nbsp;16:30</td>
		<td>Contributed Talk</td>
		<td>Daiki Kimura, Subhajit Chaudhury, Akifumi Wachi, Ryosuke Kohita, Asim Munawar, Michiaki Tatsubori, Alexander G Gray<br><b>Reinforcement Learning with External Knowledge by using Logical Neural Networks</b></td>
	</tr>
	<tr>
		<td>&nbsp;16:50</td>
		<td>Contributed Talk</td>
		<td>Thomas B Wei, Taylor Kessler Faulkner, Andrea Thomaz<br><b>Deep Policy Shaping</b></td>
	</tr>
	<tr>
		<td>&nbsp;17:10</td>
		<td>&nbsp;Closing Remarks</td>
		<td>&nbsp;<a href="https://kbrl.github.io/organizers/">KBRL Organizers</a></td>
	</tr>
	<tr>
		<td>&nbsp;17:15</td>
		<td>&nbsp;End</td>
		<td></td>
	</tr>
	</tbody>
</table>

