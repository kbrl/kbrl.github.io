---
layout: page
title: Schedule
permalink: /schedule/
---

**KBRL Workshop will be held virtually on 7th January 2020 (9:00am - 2:30pm Japan Time)**

**[Time Zone Converter (Workshop Start Time)](https://www.timeanddate.com/worldclock/converter.html?iso=20210107T000000&p1=248&p2=179&p3=224&p4=136&p5=33&p6=233&p7=195&p8=240&p9=70&p10=53&p11=176&p12=166)**

<table style="text-align: center">
	<caption></caption>
	<thead>
	<tr>
		<th>Time<br>(JST,&nbsp;GMT+09:00)</th>
		<th>Category</th>
		<th>Title & Speaker(s)</th>
	</tr>
	</thead>
	<tbody>
	<tr style="background-color: #ffebfc;">
		<td>09:00</td>
		<td>Opening Remarks</td>
		<td><a href="https://kbrl.github.io/organizers/">KBRL Organizers</a></td>
	</tr>
	<tr style="background-color: #e9fad2;">
		<td>09:05</td>
		<td>Invited Talk</td>
		<td><a href="https://www.linkedin.com/in/alexander-gray-b554b64/">Alexander Gray</a>, <a href="https://researcher.watson.ibm.com/researcher/view.php?person=jp-MICH">Michiaki Tatsubori</a>, IBM Research</td>
	</tr>		
	<tr style="background-color: #f9fade;">
		<td>09:45</td>
		<td>Contributed Talk</td>
		<td>I-Chao Shen, Shu-Hsuan Hsu, Bing-Yu Chen<br><b>Transferring Deep Reinforcement Learning with Adversarial Objective and Augmentation</b>  (<a href="https://kbrl.github.io/papers/01-KBRL.pdf">PDF</a>)</td>
	</tr>	
	<tr style="background-color: #f9fade;">
		<td>10:00</td>
		<td>Contributed Talk</td>
		<td>Prithviraj V Ammanabrolu, Ethan Tien, Zhaochen Luo, Mark Riedl<br><b>How To Avoid Being Eaten By a Grue: Exploration Strategies for Text-Adventure Agents</b>
 (<a href="https://kbrl.github.io/papers/03-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>10:15</td>
		<td>Contributed Talk</td>
		<td>Bernardo Esteves, Francisco S. Melo<br><b>Revisiting “Recurrent World Models Facilitate Policy Evolution”</b> (<a href="https://kbrl.github.io/papers/05-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #e9fad2;">
		<td>10:30</td>
		<td>Invited Talk</td>
		<td><a href="https://www.cs.princeton.edu/~karthikn/">Karthik Narasimhan</a>, Assistant Professor, Computer Science, Princeton NLP</td>
	</tr>					
	<tr style="background-color: #f9fade;">
		<td>11:00</td>
		<td>Contributed Talk</td>
		<td>Duc Thien Nguyen, Desmond Cai, Shiau Hong Lim, Laura Wynter<br><b>Deep Recurrent Policy Search for Portfolio Optimization</b> (<a href="https://kbrl.github.io/papers/06-KBRL.pdf">PDF</a>)</td>	
	</tr>		
	<tr style="background-color: #f9fade;">
		<td>11:15</td>
		<td>Contributed Talk</td>
		<td>Jakob J Hollenstein, Sayantan Auddy, Matteo Saveriano, Erwan Renaudo, Justus Piater<br><b>How do Offline Measures for Exploration in Reinforcement Learning behave?</b> (<a href="https://kbrl.github.io/papers/07-KBRL.pdf">PDF</a>)</td>
	</tr>	
	<tr style="background-color: #e9fad2;">
		<td>11:30</td>
		<td>Invited Talk</td>
		<td><a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/svlevine.html">Sergey Levine</a>, Assistant Professor, UC Berkeley<br><b>Offline Reinforcement Learning: Incorporating Knowledge from Data into RL</b></td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>12:00</td>
		<td>Contributed Talk</td>
		<td>Corentin Sautier, Don Joven Agravante, Michiaki Tatsubori<br><b>State Prediction in TextWorld with a Predicate-Logic Pointer Network Architecture</b> (<a href="https://kbrl.github.io/papers/08-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>12:15</td>
		<td>Contributed Talk</td>
		<td>Minori Narita, Daiki Kimura<br><b>Learning from Failure: Introducing Failure Ratio in Reinforcement Learning</b> (<a href="https://kbrl.github.io/papers/09-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>12:30</td>
		<td>Contributed Talk</td>
		<td>Corentin Sautier, Don Joven Agravante, Michiaki Tatsubori<br><b>Towards Logical Model-based Reinforcement Learning: Lifted Operator Models</b> (<a href="https://kbrl.github.io/papers/10-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #e9fad2;">
		<td>12:45</td>
		<td>Invited Talk</td>
		<td><a href="https://scholar.google.co.jp/citations?user=Khb7qw8AAAAJ&hl=ja">Masashi Hamaya</a>, <a href="https://scholar.google.co.jp/citations?user=VVoeVYIAAAAJ&hl=ja">Yoshihisa Ijiri</a>,  OMRON SINICX Corp. <br><b>Soft robotic learning for industrial assembly.</b></td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>13:15</td>
		<td>Contributed Talk</td>
		<td>Daiki Kimura, Subhajit Chaudhury, Akifumi Wachi, Ryosuke Kohita, Asim Munawar, Michiaki Tatsubori, Alexander G Gray<br><b>Reinforcement Learning with External Knowledge by using Logical Neural Networks</b> (<a href="https://kbrl.github.io/papers/11-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #f9fade;">
		<td>13:30</td>
		<td>Contributed Talk</td>
		<td>Thomas B Wei, Taylor Kessler Faulkner, Andrea Thomaz<br><b>Deep Policy Shaping</b> (<a href="https://kbrl.github.io/papers/12-KBRL.pdf">PDF</a>)</td>
	</tr>
	<tr style="background-color: #e9fad2;">
		<td>13:45</td>
		<td>Invited Talk</td>
		<td><a href="https://ogata-lab.jp/">Tetsuya Ogata</a>, Waseda University<br><b>Deep Predictive Learning and Robot Applications</b></td>
	</tr>
	<tr style="background-color: #ffebfc;">
		<td>14:15</td>
		<td>Closing Remarks</td>
		<td><a href="https://kbrl.github.io/organizers/">KBRL Organizers</a></td>
	</tr>
	<tr style="background-color: #ededed;">
		<td>14:20</td>
		<td>End</td>
		<td></td>
	</tr>
	</tbody>
</table>

